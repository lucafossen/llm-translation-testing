{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2256,
     "status": "ok",
     "timestamp": 1747346107770,
     "user": {
      "displayName": "Luca Fossen",
      "userId": "05839406467121902627"
     },
     "user_tz": -120
    },
    "id": "96cT4dwlcEOi",
    "outputId": "ebc26802-75d3-478a-998d-e8e47a005f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "/content/drive/Othercomputers/lucas-yoga/Work/Te Taka & Albert LLM project/llm-translation-testing\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Comment out if not using colab\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    # Specific for luca's computer\n",
    "    %cd \"/content/drive/Othercomputers/lucas-yoga/Work/Te Taka & Albert LLM project/llm-translation-testing\"\n",
    "    using_colab = True\n",
    "except:\n",
    "    print(\"Not using Google Colab\")\n",
    "    using_colab = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7031,
     "status": "ok",
     "timestamp": 1747346114814,
     "user": {
      "displayName": "Luca Fossen",
      "userId": "05839406467121902627"
     },
     "user_tz": -120
    },
    "id": "ToNAuH75cEOg",
    "outputId": "9b682b01-8c60-4b04-84b7-35263a784259"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: iso639-lang in /usr/local/lib/python3.11/dist-packages (2.6.0)\n",
      "Requirement already satisfied: replicate in /usr/local/lib/python3.11/dist-packages (1.0.6)\n",
      "Requirement already satisfied: httpx<1,>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from replicate) (24.2)\n",
      "Requirement already satisfied: pydantic>1.10.7 in /usr/local/lib/python3.11/dist-packages (from replicate) (2.11.4)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from replicate) (4.13.2)\n",
      "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (4.9.0)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.21.0->replicate) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.21.0->replicate) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>1.10.7->replicate) (0.4.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.21.0->replicate) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install iso639-lang\n",
    "!pip install replicate\n",
    "!pip install ctransformers[cuda]>=0.2.24\n",
    "#!pip install ctransformers>=0.2.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1747346114927,
     "user": {
      "displayName": "Luca Fossen",
      "userId": "05839406467121902627"
     },
     "user_tz": -120
    },
    "id": "2iKArCKWcEOi",
    "outputId": "479cd412-35b7-49db-ffd2-14471820a49e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu May 15 21:55:14 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
      "| N/A   50C    P8             17W /   72W |       0MiB /  23034MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 7917,
     "status": "ok",
     "timestamp": 1747346122846,
     "user": {
      "displayName": "Luca Fossen",
      "userId": "05839406467121902627"
     },
     "user_tz": -120
    },
    "id": "7m5Yc3uxcEOi"
   },
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747346122863,
     "user": {
      "displayName": "Luca Fossen",
      "userId": "05839406467121902627"
     },
     "user_tz": -120
    },
    "id": "cZWyjaZsdXiI"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "            'run_tasks': False,\n",
    "            'run_evaluation': True,\n",
    "            'viz_output_dir': 'output_graphs',\n",
    "            'run_bootstrap': False, # Not implemented yet\n",
    "            'models':\n",
    "                [\n",
    "                LLaMA2_13B_Chat_HF,\n",
    "                TheBlokeLlama2_13B_chat_Q8_0_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q6_K_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q5_K_M_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q5_K_S_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q5_0_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q4_K_M_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q4_K_S_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q4_0_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q3_K_L_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q3_K_M_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q3_K_S_GGUF,\n",
    "                TheBlokeLlama2_13B_chat_Q2_K_GGUF,\n",
    "                ],\n",
    "\n",
    "            'langs':\n",
    "                ['eng_Latn', 'mri_Latn'], # English, Maori, Norwegian\n",
    "\n",
    "            'stop_sequence': '\\n'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 20375,
     "status": "ok",
     "timestamp": 1747346143240,
     "user": {
      "displayName": "Luca Fossen",
      "userId": "05839406467121902627"
     },
     "user_tz": -120
    },
    "id": "pkrzQJDwcEOj",
    "outputId": "87b9208e-f6d6-41d6-b580-944988bfa0a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result file results/eng_mri_LLaMA 2 13B Chat - HF.result.json exists\n",
      "Loading existing results from results/eng_mri_LLaMA 2 13B Chat - HF.result.json... Loaded results.\n",
      "Result file results/mri_eng_LLaMA 2 13B Chat - HF.result.json exists\n",
      "Loading existing results from results/mri_eng_LLaMA 2 13B Chat - HF.result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q8_0 (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q8_0 (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q8_0 (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q8_0 (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q6_K (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q6_K (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q6_K (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q6_K (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q5_K_M (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q5_K_M (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q5_K_M (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q5_K_M (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q5_K_S (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q5_K_S (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q5_K_S (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q5_K_S (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q5_0 (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q5_0 (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q5_0 (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q5_0 (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q4_K_M (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q4_K_M (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q4_K_M (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q4_K_M (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q4_K_S (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q4_K_S (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q4_K_S (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q4_K_S (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q4_0 (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q4_0 (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q4_0 (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q4_0 (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_L (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_L (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_L (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_L (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_M (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_M (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_M (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_M (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_S (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_S (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_S (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_S (GGUF).result.json... Loaded results.\n",
      "Result file results/eng_mri_TheBloke Llama2 13B Chat - Q2_K (GGUF).result.json exists\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q2_K (GGUF).result.json... Loaded results.\n",
      "Result file results/mri_eng_TheBloke Llama2 13B Chat - Q2_K (GGUF).result.json exists\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q2_K (GGUF).result.json... Loaded results.\n",
      "Created tasks\n",
      "Loading existing results from results/eng_mri_LLaMA 2 13B Chat - HF.result.json... Loaded results.\n",
      "Loaded results/eng_mri_LLaMA 2 13B Chat - HF.result.json\n",
      "Loading existing results from results/mri_eng_LLaMA 2 13B Chat - HF.result.json... Loaded results.\n",
      "Loaded results/mri_eng_LLaMA 2 13B Chat - HF.result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q8_0 (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q8_0 (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q8_0 (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q8_0 (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q6_K (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q6_K (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q6_K (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q6_K (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q5_K_M (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q5_K_M (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q5_K_M (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q5_K_M (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q5_K_S (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q5_K_S (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q5_K_S (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q5_K_S (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q5_0 (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q5_0 (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q5_0 (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q5_0 (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q4_K_M (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q4_K_M (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q4_K_M (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q4_K_M (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q4_K_S (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q4_K_S (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q4_K_S (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q4_K_S (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q4_0 (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q4_0 (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q4_0 (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q4_0 (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_L (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_L (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_L (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_L (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_M (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_M (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_M (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_M (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_S (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q3_K_S (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_S (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q3_K_S (GGUF).result.json\n",
      "Loading existing results from results/eng_mri_TheBloke Llama2 13B Chat - Q2_K (GGUF).result.json... Loaded results.\n",
      "Loaded results/eng_mri_TheBloke Llama2 13B Chat - Q2_K (GGUF).result.json\n",
      "Loading existing results from results/mri_eng_TheBloke Llama2 13B Chat - Q2_K (GGUF).result.json... Loaded results.\n",
      "Loaded results/mri_eng_TheBloke Llama2 13B Chat - Q2_K (GGUF).result.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 47031.97it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 104055.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori LLaMA 2 13B Chat - HF\n",
      "Average BLEU score: 2.3859\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 135446.92it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 116967.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English LLaMA 2 13B Chat - HF\n",
      "Average BLEU score: 5.3554\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 52627.06it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 98410.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q8_0 (GGUF)\n",
      "Average BLEU score: 2.6183\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 142691.22it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 134120.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q8_0 (GGUF)\n",
      "Average BLEU score: 4.6265\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 52711.37it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 72624.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q6_K (GGUF)\n",
      "Average BLEU score: 2.5274\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 143827.45it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 137384.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q6_K (GGUF)\n",
      "Average BLEU score: 4.6128\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 52407.44it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 84958.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q5_K_M (GGUF)\n",
      "Average BLEU score: 2.4359\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 140313.90it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 135732.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q5_K_M (GGUF)\n",
      "Average BLEU score: 4.7598\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 53943.29it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 98064.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q5_K_S (GGUF)\n",
      "Average BLEU score: 2.3808\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 149243.54it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 139764.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q5_K_S (GGUF)\n",
      "Average BLEU score: 4.6396\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 50609.10it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 95258.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q5_0 (GGUF)\n",
      "Average BLEU score: 2.4191\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 137938.24it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 135954.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q5_0 (GGUF)\n",
      "Average BLEU score: 4.5904\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 53225.61it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 106099.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q4_K_M (GGUF)\n",
      "Average BLEU score: 1.7302\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 131592.13it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 126633.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q4_K_M (GGUF)\n",
      "Average BLEU score: 4.3973\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 51927.23it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 107244.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q4_K_S (GGUF)\n",
      "Average BLEU score: 1.8067\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 141013.11it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 126656.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q4_K_S (GGUF)\n",
      "Average BLEU score: 4.5804\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 52951.38it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 101636.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q4_0 (GGUF)\n",
      "Average BLEU score: 2.1185\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 142744.00it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 123573.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q4_0 (GGUF)\n",
      "Average BLEU score: 4.4167\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 52898.59it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 96065.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q3_K_L (GGUF)\n",
      "Average BLEU score: 2.1473\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 141629.48it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 127283.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q3_K_L (GGUF)\n",
      "Average BLEU score: 4.5549\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 51071.89it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 114673.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q3_K_M (GGUF)\n",
      "Average BLEU score: 1.6582\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 147974.05it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 148273.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q3_K_M (GGUF)\n",
      "Average BLEU score: 4.5522\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 51813.14it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 113087.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q3_K_S (GGUF)\n",
      "Average BLEU score: 1.8353\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 134379.20it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 139543.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q3_K_S (GGUF)\n",
      "Average BLEU score: 4.0417\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 52324.75it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 101490.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English -> Maori TheBloke Llama2 13B Chat - Q2_K (GGUF)\n",
      "Average BLEU score: 1.9933\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Splitting references: 100%|██████████| 1012/1012 [00:00<00:00, 137576.11it/s]\n",
      "Splitting candidates: 100%|██████████| 1012/1012 [00:00<00:00, 123923.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maori -> English TheBloke Llama2 13B Chat - Q2_K (GGUF)\n",
      "Average BLEU score: 3.7470\n",
      "\n",
      "\n",
      "Model LLaMA 2 13B Chat - HF: Average bleu score: 3.8706\n",
      "Model TheBloke Llama2 13B Chat - Q8_0 (GGUF): Average bleu score: 3.6224\n",
      "Model TheBloke Llama2 13B Chat - Q6_K (GGUF): Average bleu score: 3.5701\n",
      "Model TheBloke Llama2 13B Chat - Q5_K_M (GGUF): Average bleu score: 3.5979\n",
      "Model TheBloke Llama2 13B Chat - Q5_K_S (GGUF): Average bleu score: 3.5102\n",
      "Model TheBloke Llama2 13B Chat - Q5_0 (GGUF): Average bleu score: 3.5047\n",
      "Model TheBloke Llama2 13B Chat - Q4_K_M (GGUF): Average bleu score: 3.0637\n",
      "Model TheBloke Llama2 13B Chat - Q4_K_S (GGUF): Average bleu score: 3.1936\n",
      "Model TheBloke Llama2 13B Chat - Q4_0 (GGUF): Average bleu score: 3.2676\n",
      "Model TheBloke Llama2 13B Chat - Q3_K_L (GGUF): Average bleu score: 3.3511\n",
      "Model TheBloke Llama2 13B Chat - Q3_K_M (GGUF): Average bleu score: 3.1052\n",
      "Model TheBloke Llama2 13B Chat - Q3_K_S (GGUF): Average bleu score: 2.9385\n",
      "Model TheBloke Llama2 13B Chat - Q2_K (GGUF): Average bleu score: 2.8702\n",
      "Pair ('eng_Latn', 'mri_Latn'): Average bleu score: 2.1582\n",
      "Pair ('mri_Latn', 'eng_Latn'): Average bleu score: 4.5288\n",
      "Language eng_Latn: Average bleu score: 3.3435\n",
      "Language mri_Latn: Average bleu score: 3.3435\n",
      "Language eng_Latn:\n",
      "\tModel LLaMA 2 13B Chat - HF: Average bleu score: 3.8706\n",
      "\tModel TheBloke Llama2 13B Chat - Q8_0 (GGUF): Average bleu score: 3.6224\n",
      "\tModel TheBloke Llama2 13B Chat - Q6_K (GGUF): Average bleu score: 3.5701\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_K_M (GGUF): Average bleu score: 3.5979\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_K_S (GGUF): Average bleu score: 3.5102\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_0 (GGUF): Average bleu score: 3.5047\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_K_M (GGUF): Average bleu score: 3.0637\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_K_S (GGUF): Average bleu score: 3.1936\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_0 (GGUF): Average bleu score: 3.2676\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_L (GGUF): Average bleu score: 3.3511\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_M (GGUF): Average bleu score: 3.1052\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_S (GGUF): Average bleu score: 2.9385\n",
      "\tModel TheBloke Llama2 13B Chat - Q2_K (GGUF): Average bleu score: 2.8702\n",
      "Language mri_Latn:\n",
      "\tModel LLaMA 2 13B Chat - HF: Average bleu score: 3.8706\n",
      "\tModel TheBloke Llama2 13B Chat - Q8_0 (GGUF): Average bleu score: 3.6224\n",
      "\tModel TheBloke Llama2 13B Chat - Q6_K (GGUF): Average bleu score: 3.5701\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_K_M (GGUF): Average bleu score: 3.5979\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_K_S (GGUF): Average bleu score: 3.5102\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_0 (GGUF): Average bleu score: 3.5047\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_K_M (GGUF): Average bleu score: 3.0637\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_K_S (GGUF): Average bleu score: 3.1936\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_0 (GGUF): Average bleu score: 3.2676\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_L (GGUF): Average bleu score: 3.3511\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_M (GGUF): Average bleu score: 3.1052\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_S (GGUF): Average bleu score: 2.9385\n",
      "\tModel TheBloke Llama2 13B Chat - Q2_K (GGUF): Average bleu score: 2.8702\n",
      "Model LLaMA 2 13B Chat - HF: Average chrf score: 25.9155\n",
      "Model TheBloke Llama2 13B Chat - Q8_0 (GGUF): Average chrf score: 26.4667\n",
      "Model TheBloke Llama2 13B Chat - Q6_K (GGUF): Average chrf score: 26.1526\n",
      "Model TheBloke Llama2 13B Chat - Q5_K_M (GGUF): Average chrf score: 26.4204\n",
      "Model TheBloke Llama2 13B Chat - Q5_K_S (GGUF): Average chrf score: 25.9372\n",
      "Model TheBloke Llama2 13B Chat - Q5_0 (GGUF): Average chrf score: 26.4999\n",
      "Model TheBloke Llama2 13B Chat - Q4_K_M (GGUF): Average chrf score: 24.3110\n",
      "Model TheBloke Llama2 13B Chat - Q4_K_S (GGUF): Average chrf score: 24.0746\n",
      "Model TheBloke Llama2 13B Chat - Q4_0 (GGUF): Average chrf score: 25.5350\n",
      "Model TheBloke Llama2 13B Chat - Q3_K_L (GGUF): Average chrf score: 25.6205\n",
      "Model TheBloke Llama2 13B Chat - Q3_K_M (GGUF): Average chrf score: 23.6714\n",
      "Model TheBloke Llama2 13B Chat - Q3_K_S (GGUF): Average chrf score: 23.8870\n",
      "Model TheBloke Llama2 13B Chat - Q2_K (GGUF): Average chrf score: 24.7893\n",
      "Pair ('eng_Latn', 'mri_Latn'): Average chrf score: 21.8491\n",
      "Pair ('mri_Latn', 'eng_Latn'): Average chrf score: 28.8095\n",
      "Language eng_Latn: Average chrf score: 25.3293\n",
      "Language mri_Latn: Average chrf score: 25.3293\n",
      "Language eng_Latn:\n",
      "\tModel LLaMA 2 13B Chat - HF: Average chrf score: 25.9155\n",
      "\tModel TheBloke Llama2 13B Chat - Q8_0 (GGUF): Average chrf score: 26.4667\n",
      "\tModel TheBloke Llama2 13B Chat - Q6_K (GGUF): Average chrf score: 26.1526\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_K_M (GGUF): Average chrf score: 26.4204\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_K_S (GGUF): Average chrf score: 25.9372\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_0 (GGUF): Average chrf score: 26.4999\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_K_M (GGUF): Average chrf score: 24.3110\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_K_S (GGUF): Average chrf score: 24.0746\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_0 (GGUF): Average chrf score: 25.5350\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_L (GGUF): Average chrf score: 25.6205\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_M (GGUF): Average chrf score: 23.6714\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_S (GGUF): Average chrf score: 23.8870\n",
      "\tModel TheBloke Llama2 13B Chat - Q2_K (GGUF): Average chrf score: 24.7893\n",
      "Language mri_Latn:\n",
      "\tModel LLaMA 2 13B Chat - HF: Average chrf score: 25.9155\n",
      "\tModel TheBloke Llama2 13B Chat - Q8_0 (GGUF): Average chrf score: 26.4667\n",
      "\tModel TheBloke Llama2 13B Chat - Q6_K (GGUF): Average chrf score: 26.1526\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_K_M (GGUF): Average chrf score: 26.4204\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_K_S (GGUF): Average chrf score: 25.9372\n",
      "\tModel TheBloke Llama2 13B Chat - Q5_0 (GGUF): Average chrf score: 26.4999\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_K_M (GGUF): Average chrf score: 24.3110\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_K_S (GGUF): Average chrf score: 24.0746\n",
      "\tModel TheBloke Llama2 13B Chat - Q4_0 (GGUF): Average chrf score: 25.5350\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_L (GGUF): Average chrf score: 25.6205\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_M (GGUF): Average chrf score: 23.6714\n",
      "\tModel TheBloke Llama2 13B Chat - Q3_K_S (GGUF): Average chrf score: 23.8870\n",
      "\tModel TheBloke Llama2 13B Chat - Q2_K (GGUF): Average chrf score: 24.7893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/content/drive/Othercomputers/lucas-yoga/Work/Te Taka & Albert LLM project/llm-translation-testing/visualization.py:41: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(models, rotation=45, ha='right')  # Rotate labels to prevent overlap\n",
      "/content/drive/Othercomputers/lucas-yoga/Work/Te Taka & Albert LLM project/llm-translation-testing/visualization.py:41: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(models, rotation=45, ha='right')  # Rotate labels to prevent overlap\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual scores report written to output_graphs/2025-05-15_21-55-40/scores_report.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1747346143247,
     "user": {
      "displayName": "Luca Fossen",
      "userId": "05839406467121902627"
     },
     "user_tz": -120
    },
    "id": "seB0_3y_qAi3",
    "outputId": "3538ee1e-c649-4859-9c69-4b14d2595acd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747346143253,
     "user": {
      "displayName": "Luca Fossen",
      "userId": "05839406467121902627"
     },
     "user_tz": -120
    },
    "id": "ri14qwGhC2_w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1747346143260,
     "user": {
      "displayName": "Luca Fossen",
      "userId": "05839406467121902627"
     },
     "user_tz": -120
    },
    "id": "xBBncCSXeESS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
